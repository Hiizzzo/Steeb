# Implementaci√≥n de Stebe AI - Asistente Offline con Mistral 7B

## Descripci√≥n General

Este proyecto implementa un asistente virtual offline llamado "Stebe" que utiliza el modelo Mistral 7B en formato GGUF para funcionar completamente sin conexi√≥n a internet en dispositivos m√≥viles. El asistente act√∫a como un mentor personal de productividad, ayudando a organizar tareas y motivar al usuario.

## Caracter√≠sticas Principales

- ‚úÖ **100% Offline**: Funciona sin conexi√≥n a internet
- ‚úÖ **Privacidad Total**: Todas las conversaciones permanecen en el dispositivo
- ‚úÖ **Modelo Mistral 7B**: IA avanzada en formato GGUF optimizado
- ‚úÖ **Interfaz Intuitiva**: Integraci√≥n fluida con la app existente
- ‚úÖ **Fallback Inteligente**: Respuestas predefinidas cuando la IA no est√° disponible
- ‚úÖ **Streaming**: Respuestas generadas en tiempo real token por token
- ‚úÖ **Personalizaci√≥n**: System prompt especializado para productividad

## Arquitectura T√©cnica

### Stack Tecnol√≥gico
- **Frontend**: React + TypeScript + Tailwind CSS
- **M√≥vil**: Capacitor.js para apps nativas
- **IA**: llama.rn (binding de React Native para llama.cpp)
- **Modelo**: Mistral 7B Instruct v0.1 Q4_K_M (~4.3GB)
- **Sistema de Archivos**: Capacitor Filesystem API

### Componentes Principales

#### 1. `mistralService.ts`
Servicio principal que maneja:
- Descarga autom√°tica del modelo GGUF
- Inicializaci√≥n de llama.cpp
- Gesti√≥n del contexto de conversaci√≥n
- Generaci√≥n de respuestas streaming
- Limpieza de recursos

#### 2. `StebeAI.tsx`
Componente UI para:
- Configuraci√≥n e inicializaci√≥n del modelo
- Indicadores de progreso de descarga
- Control de estado (activado/desactivado)
- Generaci√≥n de mensajes motivacionales

#### 3. `ChatPage.tsx` (Mejorado)
P√°gina de chat con:
- Integraci√≥n con el modelo AI
- Modo AI/Fallback
- Indicadores visuales de estado
- Panel de configuraci√≥n expandible

## System Prompt de Stebe

El asistente utiliza un prompt personalizado que lo configura como:

- **Rol**: Jefe personal/mentor de productividad
- **Personalidad**: Profesional pero cercano, motivador y exigente
- **Idioma**: Siempre en espa√±ol
- **Especializaci√≥n**: Gesti√≥n de tareas, organizaci√≥n personal, motivaci√≥n
- **Limitaciones**: Solo temas de productividad personal

## Instrucciones de Instalaci√≥n

### 1. Dependencias Requeridas

```bash
# Instalar dependencias espec√≠ficas de IA
npm install llama.rn @capacitor/filesystem @capacitor/device

# Verificar que Capacitor est√© configurado
npm install @capacitor/core @capacitor/cli @capacitor/android @capacitor/ios
```

### 2. Configuraci√≥n de Capacitor

Aseg√∫rate de que `capacitor.config.ts` incluya:

```typescript
plugins: {
  Filesystem: {
    ioTimeout: 60000 // Para descargas grandes
  }
}
```

### 3. Permisos de Android

En `android/app/src/main/AndroidManifest.xml`:

```xml
<uses-permission android:name="android.permission.INTERNET" />
<uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" />
<uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE" />
```

### 4. Configuraci√≥n de iOS

En `ios/App/App/Info.plist`:

```xml
<key>NSAppTransportSecurity</key>
<dict>
    <key>NSAllowsArbitraryLoads</key>
    <true/>
</dict>
```

## Uso del Sistema

### 1. Primera Configuraci√≥n

1. Ir a la p√°gina de chat (`/chat`)
2. Hacer clic en el bot√≥n de configuraci√≥n (‚öôÔ∏è)
3. Activar "Stebe AI" - iniciar√° descarga autom√°tica
4. Esperar completaci√≥n (puede tomar 5-10 minutos seg√∫n conexi√≥n)

### 2. Uso Normal

- **Modo AI Activado**: Respuestas generadas por Mistral 7B
- **Modo AI Desactivado**: Respuestas predefinidas inteligentes
- **Indicador Visual**: Icono de cerebro (üß†) cuando AI est√° activo
- **Fallback Autom√°tico**: Si AI falla, usa respuestas predefinidas

### 3. Comandos y Funciones

- **Consejos Motivacionales**: Bot√≥n "Pedirle consejo a Stebe"
- **Chat Libre**: Cualquier mensaje sobre productividad
- **Gesti√≥n de Tareas**: Preguntas sobre organizaci√≥n y metas
- **Motivaci√≥n**: Apoyo y consejos personalizados

## Optimizaciones de Rendimiento

### 1. Modelo Optimizado
- **Formato Q4_K_M**: Balance entre calidad y tama√±o
- **Contexto Limitado**: 2048 tokens para mayor velocidad
- **CPU-Only**: Compatible con todos los dispositivos

### 2. Gesti√≥n de Memoria
- **use_mlock**: Mantiene modelo en RAM
- **Limpieza Autom√°tica**: Libera recursos al cerrar
- **Context Pooling**: Reutiliza contexto entre conversaciones

### 3. UI Responsiva
- **Streaming UI**: Tokens aparecen en tiempo real
- **Progress Indicators**: Feedback visual durante descarga
- **Fallback Instant√°neo**: Sin interrupciones en la experiencia

## Consideraciones de Producci√≥n

### 1. Almacenamiento
- **Espacio Requerido**: ~5GB libres recomendados
- **Cache Persistente**: Modelo se mantiene entre sesiones
- **Verificaci√≥n de Espacio**: Implementar antes de descarga

### 2. Rendimiento
- **Dispositivos M√≠nimos**: 4GB RAM recomendados
- **Velocidad**: 1-3 tokens/segundo seg√∫n dispositivo
- **Bater√≠a**: Uso intensivo durante generaci√≥n

### 3. Experiencia de Usuario
- **Primera Descarga**: Advertir sobre tiempo y datos
- **Modo Offline**: Clarificar que funciona sin internet
- **Fallbacks**: Siempre mantener funcionalidad b√°sica

## Troubleshooting

### Problemas Comunes

1. **Error de Descarga**
   - Verificar conexi√≥n a internet
   - Comprobar espacio disponible
   - Reintentar descarga

2. **Modelo No Carga**
   - Verificar permisos de filesystem
   - Comprobar que el archivo est√° completo
   - Limpiar cache y redownload

3. **Respuestas Lentas**
   - Normal en dispositivos antiguos
   - Considerar usar modelo m√°s peque√±o
   - Verificar otras apps no consuman CPU

4. **Memoria Insuficiente**
   - Cerrar otras aplicaciones
   - Reiniciar dispositivo
   - Reducir context_size

## Roadmap Futuro

### Mejoras Planificadas
- [ ] Modelos m√°s peque√±os para dispositivos b√°sicos
- [ ] Fine-tuning espec√≠fico para productividad
- [ ] Integraci√≥n con calendario y tareas
- [ ] Recordatorios inteligentes basados en IA
- [ ] An√°lisis de patrones de productividad

### Optimizaciones T√©cnicas
- [ ] Quantizaci√≥n din√°mica
- [ ] Model sharding para carga parcial
- [ ] Cache inteligente de respuestas
- [ ] Compresi√≥n de contexto
- [ ] GPU acceleration para iOS

## Licencias y Cr√©ditos

- **Mistral 7B**: Apache 2.0 License
- **llama.cpp**: MIT License
- **llama.rn**: MIT License
- **React Native**: MIT License

## Soporte

Para problemas t√©cnicos o preguntas:
1. Revisar logs de consola
2. Verificar configuraci√≥n de Capacitor
3. Comprobar permisos del dispositivo
4. Consultar documentaci√≥n de llama.rn

---

**Nota**: Esta implementaci√≥n est√° optimizada para funcionar en producci√≥n manteniendo un balance entre funcionalidad avanzada y compatibilidad con dispositivos m√≥viles est√°ndar.