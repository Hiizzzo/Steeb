# âš¡ LLM.js Quick Start - 5 minutos

## ðŸŽ¯ La forma mÃ¡s rÃ¡pida

### 1. Instalar Ollama (3 min)
```
https://ollama.ai â†’ Descargar e instalar
```

### 2. Ejecutar modelo (1 min)
```bash
# Abre terminal y ejecuta:
ollama run mistral
```

### 3. Usar en tu app (1 min)
```tsx
import SteebChatLLM from '@/components/SteebChatLLM';
<SteebChatLLM />
```

## Â¡Listo! ðŸš€

Cuando abras el componente:
1. Elige **Ollama**
2. Elige tu modelo
3. Â¡Chat!

---

## Â¿Por quÃ© Ollama?

âœ… **Gratis** - Sin costo  
âœ… **Local** - Totalmente privado  
âœ… **Sin API keys** - Nada que configurar  
âœ… **Offline** - Funciona sin internet  
âœ… **RÃ¡pido** - Muy buenas respuestas  

---

## Alternativas rÃ¡pidas

### OpenAI (1 min)
1. API key en https://platform.openai.com/api/keys
2. PÃ©gala en el chat
3. Â¡Listo!

### Google Gemini (1 min)
1. API key gratis en https://makersuite.google.com/app/apikey
2. PÃ©gala en el chat
3. Â¡Listo!

---

## âœ… Checklist

- [ ] Instale Ollama
- [ ] EjecutÃ© `ollama run mistral`
- [ ] ImportÃ© `SteebChatLLM`
- [ ] AbrÃ­ el componente
- [ ] Â¡Funciona!

---

**Â¡Ya tienes Stebe AI corriendo! ðŸ”¥**
